#!/usr/bin/env python3
"""
æ™ºèƒ½åˆä½µæ‰¹é‡ä¸Šå‚³è…³æœ¬

åŠŸèƒ½ï¼š
1. è­˜åˆ¥åŒæ€§è³ªæª”æ¡ˆï¼ˆCHANGELOGã€README ç­‰ï¼‰
2. åˆä½µç‚ºå–®ä¸€ Notion é é¢
3. æ¸…æ¥šæ¨™è¨»æ‰€æœ‰ä¾†æºå‡ºè™•
4. ç”¨è¦–è¦ºå…ƒç´ å€åˆ†ä¸åŒä¾†æº
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from collections import defaultdict

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv(Path(__file__).parent.parent / '.env')

# åˆä½µè¦å‰‡ï¼šåŒé¡å‹çš„æª”æ¡ˆåç¨±
MERGE_GROUPS = {
    'CHANGELOG': ['CHANGELOG.md', 'CHANGELOG', 'changelog.md'],
    'README': ['README.md', 'README', 'readme.md'],
    'QUICKSTART': ['QUICKSTART.md', 'quickstart.md'],
    'DEPLOYMENT': ['DEPLOYMENT.md', 'DEPLOY.md', 'deployment.md'],
}

# å°ˆæ¡ˆåœ–ç¤ºæ˜ å°„
PROJECT_ICONS = {
    'KTW-bot': 'ğŸ¤–',
    'pms-api': 'ğŸ”Œ',
    'pms-api-poc': 'ğŸ”¬',
    'notion-ai-organizer': 'ğŸ“„',
}

# å°ˆæ¡ˆåˆ†é¡ï¼ˆç›®éŒ„ï¼‰
PROJECT_CATEGORIES = {
    'KTW-bot': 'Bot',
    'pms-api': 'PMS',
    'pms-api-poc': 'PMS',
    'notion-ai-organizer': 'å·¥å…·',
}

# ç›¸é—œå°ˆæ¡ˆçµ„ï¼šé€™äº›å°ˆæ¡ˆå¯ä»¥åˆä½µåŒé¡å‹æª”æ¡ˆ
RELATED_PROJECT_GROUPS = [
    ['pms-api', 'pms-api-poc'],  # PMS ç›¸é—œå°ˆæ¡ˆ
    # æœªä¾†å¯æ“´å±•ï¼š['bot-v1', 'bot-v2']
]

def are_projects_related(proj1, proj2):
    """æª¢æŸ¥å…©å€‹å°ˆæ¡ˆæ˜¯å¦ç›¸é—œ"""
    if proj1 == proj2:
        return True
    
    for group in RELATED_PROJECT_GROUPS:
        if proj1 in group and proj2 in group:
            return True
    
    return False

def get_project_category(projects):
    """ç²å–å°ˆæ¡ˆçµ„çš„åˆ†é¡æ¨™ç±¤"""
    # å¦‚æœæœ‰å¤šå€‹å°ˆæ¡ˆï¼Œå–ç¬¬ä¸€å€‹çš„åˆ†é¡
    if isinstance(projects, list) and projects:
        return PROJECT_CATEGORIES.get(projects[0], 'å…¶ä»–')
    return PROJECT_CATEGORIES.get(projects, 'å…¶ä»–')

def categorize_files(files):
    """
    æ™ºèƒ½åˆ†é¡æª”æ¡ˆï¼ˆä¸‰å±¤ç­–ç•¥ï¼‰ï¼š
    1. æŒ‰å°ˆæ¡ˆå’Œæª”æ¡ˆé¡å‹åˆ†çµ„
    2. åˆä½µç›¸é—œå°ˆæ¡ˆçš„åŒé¡å‹æª”æ¡ˆ
    3. å–®ä¸€æª”æ¡ˆç¨ç«‹ä¸Šå‚³
    """
    # ç¬¬ä¸€å±¤ï¼šæŒ‰å°ˆæ¡ˆå’Œé¡å‹åˆ†çµ„
    project_groups = defaultdict(lambda: defaultdict(list))
    standalone_files = []
    
    for file_path in files:
        path = Path(file_path)
        filename = path.name
        
        # æå–å°ˆæ¡ˆåç¨±
        project = get_project_name(file_path)
        
        # æª¢æŸ¥æ˜¯å¦å±¬æ–¼å¯åˆä½µé¡å‹
        merged = False
        for group_name, patterns in MERGE_GROUPS.items():
            if filename in patterns:
                project_groups[project][group_name].append(file_path)
                merged = True
                break
        
        if not merged:
            standalone_files.append(file_path)
    
    # ç¬¬äºŒå±¤ï¼šåˆä½µç›¸é—œå°ˆæ¡ˆ
    final_groups = {}
    
    # æŒ‰æ–‡æª”é¡å‹è™•ç†
    for doc_type in MERGE_GROUPS.keys():
        # æ”¶é›†æ‰€æœ‰æœ‰æ­¤é¡å‹æ–‡æª”çš„å°ˆæ¡ˆ
        projects_with_type = {}
        for project, groups in project_groups.items():
            if doc_type in groups:
                projects_with_type[project] = groups[doc_type]
        
        # åˆä½µç›¸é—œå°ˆæ¡ˆ
        processed_projects = set()
        
        for project in projects_with_type.keys():
            if project in processed_projects:
                continue
            
            # æ‰¾å‡ºæ‰€æœ‰ç›¸é—œå°ˆæ¡ˆ
            related_files = list(projects_with_type[project])
            related_projects = [project]
            
            for other_project in projects_with_type.keys():
                if other_project != project and other_project not in processed_projects:
                    if are_projects_related(project, other_project):
                        related_files.extend(projects_with_type[other_project])
                        related_projects.append(other_project)
                        processed_projects.add(other_project)
            
            processed_projects.add(project)
            
            # å¦‚æœæœ‰å¤šå€‹æª”æ¡ˆï¼Œå‰µå»ºåˆä½µçµ„
            if len(related_files) > 1:
                # çµ„åï¼šå¦‚æœæ˜¯ç›¸é—œå°ˆæ¡ˆï¼Œç”¨ç¬¬ä¸€å€‹å°ˆæ¡ˆå + "(å«ç›¸é—œ)"
                if len(related_projects) > 1:
                    group_key = f"{'_'.join(sorted(related_projects))}_{doc_type}"
                    display_name = f"{' + '.join(sorted(related_projects))}"
                else:
                    group_key = f"{project}_{doc_type}"
                    display_name = project
                
                # ç²å–åˆ†é¡
                category = get_project_category(related_projects)
                
                final_groups[group_key] = {
                    'projects': related_projects,
                    'display_name': display_name,
                    'category': category,
                    'type': doc_type,
                    'files': related_files
                }
            else:
                # å–®ä¸€æª”æ¡ˆ â†’ ç¨ç«‹ä¸Šå‚³
                standalone_files.extend(related_files)
    
    return final_groups, standalone_files

def get_project_name(file_path):
    """å¾è·¯å¾‘æå–å°ˆæ¡ˆåç¨±"""
    parts = Path(file_path).parts
    
    # æ‰¾åˆ° KTW-bot å¾Œçš„ç¬¬ä¸€å€‹ç›®éŒ„
    try:
        ktw_index = parts.index('KTW-bot')
        if ktw_index + 1 < len(parts):
            project = parts[ktw_index + 1]
            return project if project in PROJECT_ICONS else 'KTW-bot'
    except ValueError:
        pass
    
    return 'KTW-bot'

def merge_documents(group_info):
    """
    åˆä½µå¤šå€‹æ–‡æª”ç‚ºä¸€å€‹å…§å®¹
    
    åƒæ•¸ï¼š
        group_info: dict with 'projects', 'display_name', 'category', 'type', 'files'
    
    è¿”å›ï¼šåˆä½µå¾Œçš„ markdown å…§å®¹
    """
    display_name = group_info['display_name']
    doc_type = group_info['type']
    file_paths = group_info['files']
    projects = group_info['projects']
    category = group_info.get('category', '')
    
    print(f'ğŸ”— åˆä½µ [{category}] {display_name} - {doc_type} ({len(file_paths)} å€‹æª”æ¡ˆ)...')
    
    # æ¨™é¡Œ - åŠ ä¸Šåˆ†é¡æ¨™ç±¤
    if len(projects) > 1:
        icons = ' + '.join(PROJECT_ICONS.get(p, 'ğŸ“') for p in sorted(projects))
        merged_content = f'# [{category}] {icons} {display_name} - {doc_type}\n\n'
    else:
        icon = PROJECT_ICONS.get(projects[0], 'ğŸ“')
        merged_content = f'# [{category}] {icon} {display_name} - {doc_type}\n\n'
    
    # ä¾†æºæª”æ¡ˆåˆ—è¡¨
    merged_content += '> ğŸ“Œ **ä¾†æºæª”æ¡ˆ**ï¼š\n'
    for fp in file_paths:
        merged_content += f'> - `{fp}`\n'
    merged_content += '\n---\n\n'
    
    # é€å€‹æ·»åŠ æª”æ¡ˆå…§å®¹
    for i, file_path in enumerate(file_paths, 1):
        project = get_project_name(file_path)
        icon = PROJECT_ICONS.get(project, 'ğŸ“')
        
        print(f'   [{i}/{len(file_paths)}] è®€å–ï¼š{Path(file_path).name} ({project})')
        
        # è®€å–æª”æ¡ˆå…§å®¹
        try:
            # å˜—è©¦å¤šç¨®ç·¨ç¢¼è®€å–
            content = None
            for encoding in ['utf-8', 'utf-8-sig', 'big5', 'gbk', 'latin-1']:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except (UnicodeDecodeError, LookupError):
                    continue
            
            if content is None:
                raise ValueError(f'ç„¡æ³•ä»¥ä»»ä½•ç·¨ç¢¼è®€å–æª”æ¡ˆ')
            
            # æ¸…ç†æ§åˆ¶å­—å…ƒï¼ˆä¿ç•™æ›è¡Œå’Œtabï¼‰
            import re
            content = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f\x7f]', '', content)
            
            # ç²å–æª”æ¡ˆçš„æœ€å¾Œä¿®æ”¹æ™‚é–“ï¼ˆåŸæª”æ¡ˆæ™‚é–“ï¼Œéä¸Šå‚³æ™‚é–“ï¼‰
            import os
            from datetime import datetime
            file_mtime = os.path.getmtime(file_path)
            file_time = datetime.fromtimestamp(file_mtime).strftime('%Y-%m-%d %H:%M:%S')
            
            # æ·»åŠ å­ç« ç¯€æ¨™é¡Œï¼ˆå«åŸæª”æ¡ˆæ™‚é–“ï¼‰
            merged_content += f'## {icon} {project} - {Path(file_path).name} ({file_time})\n\n'
            merged_content += f'> ğŸ“‚ å®Œæ•´è·¯å¾‘ï¼š`{file_path}`\n'
            merged_content += f'> â° æª”æ¡ˆä¿®æ”¹æ™‚é–“ï¼š{file_time}\n\n'
            
            # æ·»åŠ å…§å®¹
            merged_content += content.strip() + '\n\n'
            
            # åˆ†éš”ç·šï¼ˆé™¤äº†æœ€å¾Œä¸€å€‹ï¼‰
            if i < len(file_paths):
                merged_content += '---\n\n'
        
        except Exception as e:
            print(f'   âš ï¸ è®€å–éŒ¯èª¤ï¼š{e}')
            merged_content += f'> âš ï¸ ç„¡æ³•è®€å–æ­¤æª”æ¡ˆï¼š{e}\n\n'
    
    return merged_content

def create_merged_page(merged_content, group_name):
    """å‰µå»ºåˆä½µå¾Œçš„ Notion é é¢"""
    from organize_and_upload import NotionAIOrganizer
    
    # å„²å­˜ç‚ºè‡¨æ™‚æª”æ¡ˆ
    temp_file = f'/tmp/merged_{group_name}.md'
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(merged_content)
    
    print(f'ğŸ“ å‰µå»º Notion é é¢...')
    
    # ä½¿ç”¨ç¾æœ‰çš„ä¸Šå‚³å·¥å…·
    organizer = NotionAIOrganizer()
    
    try:
        # ä¸Šå‚³ï¼ˆå« AI å»ºè­°ï¼‰
        organizer.process_document(temp_file, add_insights=True, mode='new')
        print(f'âœ… å®Œæˆï¼\n')
        
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        os.remove(temp_file)
        
    except Exception as e:
        print(f'âŒ éŒ¯èª¤ï¼š{e}\n')

def smart_batch_upload(limit=None):
    """æ™ºèƒ½æ‰¹é‡ä¸Šå‚³ï¼ˆå°ˆæ¡ˆåˆ†çµ„ + å…§å®¹ç›¸é—œæ€§ï¼‰"""
    from batch_upload import find_important_files
    
    print('ğŸš€ æ™ºèƒ½åˆä½µæ‰¹é‡ä¸Šå‚³ï¼ˆå°ˆæ¡ˆåˆ†çµ„æ¨¡å¼ï¼‰\n')
    
    # 1. æƒææª”æ¡ˆ
    files = find_important_files('/Users/ktw/KTW-bot')
    
    # 2. æ™ºèƒ½åˆ†é¡æª”æ¡ˆ
    merged_groups, standalone_files = categorize_files(files)
    
    print('=' * 80)
    print('ğŸ“Š ä¸Šå‚³è¨ˆåŠƒï¼ˆæŒ‰å°ˆæ¡ˆåˆ†çµ„ï¼‰')
    print('=' * 80)
    
    total_merged_files = sum(len(g['files']) for g in merged_groups.values())
    print(f'ğŸ”— åˆä½µä¸Šå‚³ï¼š{total_merged_files} å€‹æª”æ¡ˆ â†’ {len(merged_groups)} å€‹é é¢\n')
    
    for group_key, group_info in merged_groups.items():
        display_name = group_info['display_name']
        doc_type = group_info['type']
        file_count = len(group_info['files'])
        projects = group_info['projects']
        
        if len(projects) > 1:
            icons = ' + '.join(PROJECT_ICONS.get(p, 'ğŸ“') for p in sorted(projects))
            print(f'   {icons} {display_name} - {doc_type}: {file_count} å€‹æª”æ¡ˆ')
        else:
            icon = PROJECT_ICONS.get(projects[0], 'ğŸ“')
            print(f'   {icon} {display_name} - {doc_type}: {file_count} å€‹æª”æ¡ˆ')
    
    print(f'\nğŸ“„ ç¨ç«‹ä¸Šå‚³ï¼š{len(standalone_files)} å€‹æª”æ¡ˆ')
    
    if limit:
        print(f'\nâš ï¸ é™åˆ¶è™•ç†ï¼šå‰ {limit} å€‹æ“ä½œ\n')
    
    print('=' * 80 + '\n')
    
    # 3. è™•ç†åˆä½µæª”æ¡ˆ
    operations = 0
    
    if merged_groups:
        print('ğŸ”— é–‹å§‹åˆä½µä¸Šå‚³...\n')
        
        for group_key, group_info in merged_groups.items():
            if limit and operations >= limit:
                break
            
            display_name = group_info['display_name']
            doc_type = group_info['type']
            projects = group_info['projects']
            
            if len(projects) > 1:
                icons = ' + '.join(PROJECT_ICONS.get(p, 'ğŸ“') for p in sorted(projects))
                print(f'ğŸ“¦ è™•ç† {icons} {display_name} - {doc_type}...')
            else:
                icon = PROJECT_ICONS.get(projects[0], 'ğŸ“')
                print(f'ğŸ“¦ è™•ç† {icon} {display_name} - {doc_type}...')
            
            # åˆä½µå…§å®¹
            merged_content = merge_documents(group_info)
            
            # å‰µå»ºé é¢
            create_merged_page(merged_content, group_key)
            
            operations += 1
    
    # 4. è™•ç†ç¨ç«‹æª”æ¡ˆï¼ˆå¦‚æœé‚„æœ‰é…é¡ï¼‰
    if limit:
        remaining = limit - operations
    else:
        remaining = len(standalone_files)
    
    if standalone_files and remaining > 0:
        print(f'\nğŸ“„ é–‹å§‹ç¨ç«‹ä¸Šå‚³ï¼ˆå‰ {remaining} å€‹ï¼‰...\n')
        
        from organize_and_upload import NotionAIOrganizer
        organizer = NotionAIOrganizer()
        
        for i, file_path in enumerate(standalone_files[:remaining], 1):
            print(f'[{i}/{remaining}] ä¸Šå‚³ï¼š{Path(file_path).name}')
            
            try:
                organizer.process_document(file_path, add_insights=True, mode='new')
                print(f'   âœ… å®Œæˆ\n')
            except Exception as e:
                print(f'   âŒ éŒ¯èª¤ï¼š{e}\n')
    
    print('=' * 80)
    print('âœ… æ‰¹é‡ä¸Šå‚³å®Œæˆï¼')
    print('=' * 80)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='æ™ºèƒ½åˆä½µæ‰¹é‡ä¸Šå‚³')
    parser.add_argument('--limit', type=int, help='é™åˆ¶è™•ç†æ•¸é‡')
    
    args = parser.parse_args()
    
    smart_batch_upload(limit=args.limit)

if __name__ == '__main__':
    main()
